{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installation der Pakete"
      ],
      "metadata": {
        "id": "lYqYt0_67wAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Offizielles OpenAI-SDK, um über Python mit den OpenAI-APIs zu kommunizieren\n",
        "!pip install openai\n",
        "\n",
        "# HTTP-Client-Bibliothek für Python, um Web-APIs wie OpenWeatherMap abzufragen\n",
        "!pip install requests\n",
        "\n",
        "# Bibliothek für Datenvalidierung/-modellierung, die dafür sorgt dafür, dass Ausgaben in einem festen Schema (Structured Output) vorliegen\n",
        "!pip install pydantic\n",
        "\n",
        "# Hilfsbibliothek, um Listen/Tabellen als schön formatierte Texttabellen auszugeben\n",
        "!pip install tabulate"
      ],
      "metadata": {
        "id": "dISQpZD678bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports und Basis-Setup"
      ],
      "metadata": {
        "id": "988DcQY37_Mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Openai-client-klasse importieren (für Chat-Completion Aufrufe)\n",
        "from openai import OpenAI\n",
        "\n",
        "# Pydantic-Basisklasse für strikt typisierte/validierte Datamodelle\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Sorgt für strukturierte Tabellen in der Konsole\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Datum und Zeit für Zeitstempel\n",
        "from datetime import datetime\n",
        "\n",
        "# Lädt 'requests' für HTTP-Anfragen (z.B. API-Aufrufe) und 'json' zum Umwandeln zwischen JSON-Text und Python-Datenstrukturen\n",
        "import requests, json\n",
        "\n",
        "# OpenAI-Key laden\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('apikey_ab')\n",
        "\n",
        "# OpenWeatherMap API-Key\n",
        "from google.colab import userdata\n",
        "OWM_API_KEY = userdata.get('owmkey')\n",
        "\n",
        "# Standard-Stadt für die Abfrage\n",
        "CITY = \"Stuttgart\"\n",
        "\n",
        "# OpenAI-Client initialisieren\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "p1T9RNmb7-ec"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tool-Nutzung: Wetter-Tool"
      ],
      "metadata": {
        "id": "yphzHmyF8rxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definiert eine Funktion, die für eine Stadt aktuelles Wetter von OpenWeatherMap abruft\n",
        "def get_weather(city: str):\n",
        "    # Sendet eine HTTP-GET-Anfrage an die OWM-API mit Stadtname, metrischen Einheiten, deutscher Sprache und API-Key\n",
        "    resp = requests.get(\n",
        "        f\"http://api.openweathermap.org/data/2.5/weather?q={city}&units=metric&lang=de&appid={OWM_API_KEY}\",\n",
        "        timeout=15 # Beendet den Request automatisch, wenn nach 15 Sekunden keine Antwort kommt\n",
        "    )\n",
        "\n",
        "    # Wandelt die API-Antwort aus JSON in ein Python-Objekt (Dictionary) um\n",
        "    data = resp.json()\n",
        "    # Prüft, ob die Antwort fehlerfrei ist (HTTP-Code & API-Code)\n",
        "    if resp.status_code != 200 or (data.get(\"cod\") not in (200, None)):\n",
        "        msg = data.get(\"message\", f\"HTTP {resp.status_code}\") # Holt die Fehlermeldung aus der Antwort oder nutzt den HTTP-Statuscode\n",
        "        raise RuntimeError(f\"Fehler beim Abruf: {msg}\") # Bricht die Funktion mit einer Fehlermeldung ab, wenn die Abfrage scheitert\n",
        "\n",
        "    # Liest die aktuelle Temperatur in °C aus den Wetterdaten aus\n",
        "    temp = float(data[\"main\"][\"temp\"])\n",
        "\n",
        "    # Liest die Kurzbeschreibung des aktuellen Wetters aus\n",
        "    desc = data[\"weather\"][0][\"description\"]\n",
        "\n",
        "    # Erstellt ein Dictionary mit heutigem Datum und Temperatur\n",
        "    point = {\"date\": datetime.now().strftime(\"%Y-%m-%d\"), \"temp_c\": temp}\n",
        "\n",
        "    # Gibt die Wetterdaten als strukturiertes Dictionary zurück\n",
        "    return {\"city\": city, \"temperature_c\": temp, \"description\": desc, \"points\": [point]}\n",
        "\n",
        "\n",
        "# Tool-Spezifikation für das LLM (Function Calling)\n",
        "tools = [{ # Definiert eine Liste mit einem Tool, das das LLM aufrufen darf\n",
        "    \"type\": \"function\", # Legt fest, dass es sich bei diesem Tool um eine Funktion handelt\n",
        "    \"function\": {\n",
        "        \"name\": \"get_weather\", # Name des Tools, der im LLM-Aufruf referenziert wird\n",
        "        \"description\": \"Get current weather for a city (temperature + short description).\", # Beschreibung für das LLM, wofür das Tool gedacht ist\n",
        "        \"parameters\": {  # Legt das JSON-Schema für die Parameter fest, die das LLM übergeben muss\n",
        "            \"type\": \"object\", # Parameter werden als JSON-Objekt übergeben\n",
        "            \"properties\": {\"city\": {\"type\": \"string\"}}, # Erlaubtes Feld: \"city\" als String\n",
        "            \"required\": [\"city\"], # Das Feld \"city\" ist Pflicht\n",
        "            \"additionalProperties\": False # Keine weiteren Felder außer den definierten sind erlaubt\n",
        "        },\n",
        "        \"strict\": True # Erzwingt strikte Einhaltung des Schemas beim Funktionsaufruf\n",
        "    }\n",
        "}]"
      ],
      "metadata": {
        "id": "nztKwPrk8yfi"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt-Chaining"
      ],
      "metadata": {
        "id": "nmU_yd2B82Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Schritt: Erster LLM-Call entscheidet, ob/wie das Tool aufzurufen ist\n",
        "\n",
        "# Erstellt die Nachrichtenliste, die als Gesprächskontext an das LLM geschickt wird\n",
        "messages = [\n",
        "    # Systemnachricht: definiert Rolle und Stil der Antworten\n",
        "    {\"role\": \"system\", \"content\": \"You are a concise weather assistant. Keep outputs short.\"},\n",
        "    # Benutzerfrage mit der gewünschten Stadt (CITY)\n",
        "    {\"role\": \"user\", \"content\": f\"What's the current weather in {CITY}?\"}\n",
        "]\n",
        "\n",
        "# Ruft das OpenAI-API auf, um eine Chat-Antwort vom Modell zu generieren\n",
        "c1 = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\", # Modellauswahl\n",
        "    messages=messages, # Übergibt den Gesprächskontext an das Modell\n",
        "    tools=tools, # Übergibt die Liste verfügbarer Tools, die das Modell aufrufen darf\n",
        "    max_tokens=200 # Beschränkt die maximale Länge der Modellantwort\n",
        ")\n",
        "\n",
        "# 2. Schritt: Tool tatsächlich ausführen und Ergebnis zurück in den Chat geben\n",
        "\n",
        "# Iteriert über alle vom Modell vorgeschlagenen Tool-Aufrufe\n",
        "for tc in c1.choices[0].message.tool_calls or []:\n",
        "    messages.append(c1.choices[0].message) # Fügt die Assistant-Nachricht mit dem Tool-Aufruf zum Nachrichtenverlauf hinzu\n",
        "    args = json.loads(tc.function.arguments) # Parst die vom Modell als JSON gesendeten Argumente in ein Python-Dictionary\n",
        "    result = get_weather(**args)  # Führt das Wetter-Tool mit den Argumenten aus und speichert das Ergebnis\n",
        "    messages.append({\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": json.dumps(result)})  # Fügt das Tool-Ergebnis als 'tool'-Nachricht in den Nachrichtenverlauf ein"
      ],
      "metadata": {
        "id": "cewzJbmJ9EWA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structured Output"
      ],
      "metadata": {
        "id": "LCXP7GxF9H9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definiert ein Pydantic-Datenmodell für einen einzelnen Wetterdatenpunkt\n",
        "class WeatherPoint(BaseModel):\n",
        "    date: str                   # Datum als Zeichenkette\n",
        "    temp_c: float               # Temperatur in Grad Celsius als Fließkommazahl\n",
        "\n",
        "# Definiert ein Pydantic-Datenmodell für den kompletten Wetterbericht\n",
        "class WeatherReport(BaseModel):\n",
        "    city: str                        # Name der abgefragten Stadt\n",
        "    temperature_c: float             # Aktuelle Temperatur in Grad Celsius\n",
        "    description: str                 # Kurze Wetterbeschreibung\n",
        "    points: list[WeatherPoint] = []  # Liste mit Wetterpunkten (hier nur ein Eintrag für heute)\n",
        "    avg_temp_c: float                # Durchschnittstemperatur (kann vom Modell berechnet werden)\n",
        "    note: str                        # Kurze Empfehlung oder Bemerkung basierend auf der Temperatur\n",
        "\n",
        "# 3. Schritt: Zweiter LLM-Call: finale Antwort erzeugen und strikt ins Schema parsen\n",
        "\n",
        "# Ruft das OpenAI-API auf und parsed die Antwort direkt ins WeatherReport-Schema\n",
        "c2 = client.beta.chat.completions.parse(\n",
        "    model=\"gpt-4o-mini\",                  # Modellwahl\n",
        "    messages=messages,                    # Gesamter Nachrichtenverlauf (inkl. Tool-Ergebnis) als Kontext\n",
        "    tools=tools,                          # Liste der verfügbaren Tools\n",
        "    response_format=WeatherReport,        # Erwartetes Ausgabeformat: Instanz des WeatherReport-Pydantic-Modells\n",
        "    max_tokens=200                        # Maximale Länge der Antwort in Tokens begrenzen\n",
        ")\n",
        "final = c2.choices[0].message.parsed      # Extrahiert die geparste Modellantwort als WeatherReport-Objekt\n",
        "\n",
        "\n",
        "# Ausgabe bestehend aus JSON und TABELLE\n",
        "\n",
        "print(\"JSON Output:\")                     # Überschrift für die JSON-Ausgabe\n",
        "print(final.model_dump_json(indent=2))    # Gibt den WeatherReport formatiert als JSON-String aus (mit Einrückung)\n",
        "\n",
        "# Prüft, ob die Liste der Wetterpunkte nicht leer ist\n",
        "if final.points:\n",
        "    table = [[\"Datum\", \"Temp (°C)\"]] + [[p.date, p.temp_c] for p in final.points]  # Baut eine Tabellenstruktur aus den Wetterpunkten\n",
        "    print(\"\\nTabelle:\")                                                            # Überschrift für die Tabelle\n",
        "    print(tabulate(table, headers=\"firstrow\", tablefmt=\"github\"))                  # Gibt die Tabelle im Markdown-kompatiblen Format aus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmqJnbDJ4f5r",
        "outputId": "6d022ba0-c8f4-4121-de3f-0359aeac9a20"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON Output:\n",
            "{\n",
            "  \"city\": \"Stuttgart\",\n",
            "  \"temperature_c\": 18.79,\n",
            "  \"description\": \"Klarer Himmel\",\n",
            "  \"points\": [\n",
            "    {\n",
            "      \"date\": \"2025-08-11\",\n",
            "      \"temp_c\": 18.79\n",
            "    }\n",
            "  ],\n",
            "  \"avg_temp_c\": 18.79,\n",
            "  \"note\": \"\"\n",
            "}\n",
            "\n",
            "Tabelle:\n",
            "| Datum      |   Temp (°C) |\n",
            "|------------|-------------|\n",
            "| 2025-08-11 |       18.79 |\n"
          ]
        }
      ]
    }
  ]
}